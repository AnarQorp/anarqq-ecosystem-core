name: Documentation Consolidation Tests

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'scripts/ScriptGenerator.mjs'
      - 'scripts/ModuleDocumentationNormalizer.mjs'
      - 'scripts/ContentExtractionEngine.mjs'
      - 'scripts/docs-validator.mjs'
      - 'scripts/master-index-builder.mjs'
      - 'tests/docs-consolidation/**'
      - 'docs/**'
      - 'package.json'
      - 'vitest.docs-consolidation.config.ts'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'scripts/ScriptGenerator.mjs'
      - 'scripts/ModuleDocumentationNormalizer.mjs'
      - 'scripts/ContentExtractionEngine.mjs'
      - 'scripts/docs-validator.mjs'
      - 'scripts/master-index-builder.mjs'
      - 'tests/docs-consolidation/**'
      - 'docs/**'
      - 'package.json'
      - 'vitest.docs-consolidation.config.ts'

jobs:
  test:
    runs-on: ubuntu-latest
    
    strategy:
      matrix:
        node-version: [18.x, 20.x]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v4
      with:
        node-version: ${{ matrix.node-version }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Create test results directory
      run: mkdir -p test-results
      
    - name: Run documentation consolidation tests
      run: |
        npm run test:docs-consolidation:coverage
      env:
        CI: true
        
    - name: Run comprehensive test suite
      run: |
        node scripts/run-docs-consolidation-tests.mjs --ci
      env:
        CI: true
        
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.node-version }}
        path: |
          test-results/
          coverage/
        retention-days: 30
        
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v4
      if: matrix.node-version == '20.x'
      with:
        file: ./coverage/lcov.info
        flags: docs-consolidation
        name: docs-consolidation-coverage
        fail_ci_if_error: false

  validate-documentation:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Validate documentation structure
      run: npm run docs:validate:structure
      
    - name: Validate documentation completeness
      run: npm run docs:validate:enhanced
      
    - name: Validate accessibility compliance
      run: npm run docs:validate:accessibility
      
    - name: Validate link integrity
      run: npm run docs:validate:links
      
    - name: Generate documentation index
      run: npm run docs:index:build
      
    - name: Validate generated scripts
      run: |
        if [ -d "docs/video-scripts" ]; then
          npm run docs:validate:scripts
        else
          echo "No video scripts found, skipping validation"
        fi

  performance-benchmarks:
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Run performance benchmarks
      run: |
        echo "Running script generation benchmark..."
        node -e "
          const { ScriptGenerator } = require('./scripts/ScriptGenerator.mjs');
          const { performance } = require('perf_hooks');
          
          (async () => {
            const generator = new ScriptGenerator();
            await generator.init();
            
            const start = performance.now();
            await generator.generateAllScripts();
            const end = performance.now();
            
            const duration = end - start;
            const scriptsGenerated = generator.generatedScripts.length;
            
            console.log(\`Performance Results:\`);
            console.log(\`- Duration: \${duration.toFixed(2)}ms\`);
            console.log(\`- Scripts Generated: \${scriptsGenerated}\`);
            console.log(\`- Average per Script: \${(duration / scriptsGenerated).toFixed(2)}ms\`);
            
            // Fail if performance is below threshold
            if (duration > 30000) {
              console.error('❌ Performance benchmark failed: Script generation took too long');
              process.exit(1);
            }
            
            console.log('✅ Performance benchmark passed');
          })();
        "
        
    - name: Run documentation processing benchmark
      run: |
        echo "Running documentation processing benchmark..."
        node -e "
          const { ModuleDocumentationNormalizer } = require('./scripts/ModuleDocumentationNormalizer.mjs');
          const { performance } = require('perf_hooks');
          
          (async () => {
            const normalizer = new ModuleDocumentationNormalizer();
            
            const start = performance.now();
            await normalizer.normalizeAllDocumentation();
            const end = performance.now();
            
            const duration = end - start;
            const filesProcessed = normalizer.processedFiles.length;
            
            console.log(\`Processing Results:\`);
            console.log(\`- Duration: \${duration.toFixed(2)}ms\`);
            console.log(\`- Files Processed: \${filesProcessed}\`);
            console.log(\`- Average per File: \${filesProcessed > 0 ? (duration / filesProcessed).toFixed(2) : 0}ms\`);
            
            if (duration > 15000) {
              console.error('❌ Processing benchmark failed: Documentation processing took too long');
              process.exit(1);
            }
            
            console.log('✅ Processing benchmark passed');
          })();
        "

  quality-gates:
    runs-on: ubuntu-latest
    needs: [test, validate-documentation]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Download test results
      uses: actions/download-artifact@v4
      with:
        name: test-results-20.x
        path: test-results/
        
    - name: Validate test coverage thresholds
      run: |
        if [ -f "test-results/docs-consolidation-coverage-report.json" ]; then
          node -e "
            const fs = require('fs');
            const report = JSON.parse(fs.readFileSync('test-results/docs-consolidation-coverage-report.json', 'utf8'));
            
            const thresholds = {
              lines: 70,
              functions: 70,
              branches: 70,
              statements: 70
            };
            
            let failed = false;
            
            Object.entries(thresholds).forEach(([metric, threshold]) => {
              const actual = report.summary[metric].pct;
              if (actual < threshold) {
                console.error(\`❌ \${metric} coverage \${actual}% is below threshold \${threshold}%\`);
                failed = true;
              } else {
                console.log(\`✅ \${metric} coverage \${actual}% meets threshold \${threshold}%\`);
              }
            });
            
            if (failed) {
              process.exit(1);
            }
            
            console.log('✅ All coverage thresholds met');
          "
        else
          echo "⚠️ Coverage report not found, skipping threshold validation"
        fi
        
    - name: Validate test success rate
      run: |
        if [ -f "test-results/docs-consolidation-test-report.json" ]; then
          node -e "
            const fs = require('fs');
            const report = JSON.parse(fs.readFileSync('test-results/docs-consolidation-test-report.json', 'utf8'));
            
            const { total, failed } = report.summary;
            const successRate = total > 0 ? ((total - failed) / total) * 100 : 100;
            
            console.log(\`Test Success Rate: \${successRate.toFixed(2)}%\`);
            
            if (successRate < 95) {
              console.error(\`❌ Test success rate \${successRate.toFixed(2)}% is below 95% threshold\`);
              process.exit(1);
            }
            
            console.log('✅ Test success rate meets threshold');
          "
        else
          echo "⚠️ Test report not found, skipping success rate validation"
        fi

  security-scan:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Run security audit
      run: |
        npm audit --audit-level moderate
        
    - name: Scan for secrets
      uses: trufflesecurity/trufflehog@main
      with:
        path: ./
        base: main
        head: HEAD
        extra_args: --debug --only-verified

  deployment-readiness:
    runs-on: ubuntu-latest
    needs: [quality-gates, security-scan, performance-benchmarks]
    if: github.ref == 'refs/heads/main'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20.x'
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Validate deployment readiness
      run: |
        echo "Validating deployment readiness..."
        
        # Run comprehensive validation
        npm run docs:validate:comprehensive
        
        # Generate documentation artifacts
        npm run docs:generate
        npm run docs:index:build
        
        # Validate generated artifacts
        if [ ! -f "docs/README.md" ]; then
          echo "❌ Missing docs/README.md"
          exit 1
        fi
        
        if [ ! -f "docs/INDEX.md" ]; then
          echo "❌ Missing docs/INDEX.md"
          exit 1
        fi
        
        echo "✅ Deployment readiness validated"
        
    - name: Create deployment summary
      run: |
        echo "## 🚀 Deployment Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### ✅ All Quality Gates Passed" >> $GITHUB_STEP_SUMMARY
        echo "- Tests: Passed" >> $GITHUB_STEP_SUMMARY
        echo "- Coverage: Above thresholds" >> $GITHUB_STEP_SUMMARY
        echo "- Documentation: Validated" >> $GITHUB_STEP_SUMMARY
        echo "- Performance: Within limits" >> $GITHUB_STEP_SUMMARY
        echo "- Security: No issues found" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### 📊 Metrics" >> $GITHUB_STEP_SUMMARY
        echo "- Node.js Version: 20.x" >> $GITHUB_STEP_SUMMARY
        echo "- Build Time: $(date)" >> $GITHUB_STEP_SUMMARY
        echo "- Commit: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY